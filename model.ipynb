{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from recsys_utils import load_Book_List_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New user ratings:\n",
      "\n",
      "Rated 5.0 for  Harry Potter and the Half-Blood Prince (Harry Potter  #6)\n",
      "Rated 2.0 for  Harry Potter and the Order of the Phoenix (Harry Potter  #5)\n",
      "Rated 5.0 for  Harry Potter and the Chamber of Secrets (Harry Potter  #2)\n",
      "Rated 5.0 for  Harry Potter and the Prisoner of Azkaban (Harry Potter  #3)\n",
      "Rated 3.0 for  Harry Potter Boxed Set  Books 1-5 (Harry Potter  #1-5)\n",
      "Rated 5.0 for  Unauthorized Harry Potter Book Seven News: \"Half-Blood Prince\" Analysis and Speculation\n",
      "Rated 2.0 for  Harry Potter Collection (Harry Potter  #1-6)\n",
      "Rated 5.0 for  The Ultimate Hitchhiker's Guide: Five Complete Novels and One Story (Hitchhiker's Guide to the Galaxy  #1-5)\n",
      "Rated 5.0 for  The Ultimate Hitchhiker's Guide to the Galaxy (Hitchhiker's Guide to the Galaxy  #1-5)\n",
      "Rated 3.0 for  The Hitchhiker's Guide to the Galaxy (Hitchhiker's Guide to the Galaxy  #1)\n",
      "Rated 1.0 for  The Hitchhiker's Guide to the Galaxy (Hitchhiker's Guide to the Galaxy  #1)\n",
      "Rated 1.0 for  The Ultimate Hitchhiker's Guide (Hitchhiker's Guide to the Galaxy  #1-5)\n",
      "Rated 5.0 for  A Short History of Nearly Everything\n"
     ]
    }
   ],
   "source": [
    "bookList, bookList_df = load_Book_List_pd()\n",
    "\n",
    "my_ratings = np.zeros(11128)          #  Initialize my ratings\n",
    "\n",
    "# For example, Harry Potter and the Half-Blood Prince (Harry Potter  #6) has ID 1, so to rate it \"5\", you can set\n",
    "my_ratings[1] = 5 \n",
    "\n",
    "#Or suppose you did not enjoy Persuasion (2007), you can set\n",
    "my_ratings[2] = 2;\n",
    "\n",
    "# We have selected a few movies we liked / did not like and the ratings we\n",
    "# gave are as follows:\n",
    "my_ratings[4]  = 5   # Lord of the Rings: The Return of the King, The\n",
    "my_ratings[5]  = 5   # Shrek (2001)\n",
    "my_ratings[8] = 3   # Inception\n",
    "my_ratings[9] = 5   # Incredibles, The (2004)\n",
    "my_ratings[10]  = 2   # Amelie (Fabuleux destin d'Amélie Poulain, Le)\n",
    "my_ratings[12]  = 5   # Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
    "my_ratings[13]  = 5   # Harry Potter and the Chamber of Secrets (2002)\n",
    "my_ratings[14]  = 3   # Eternal Sunshine of the Spotless Mind (2004)\n",
    "my_ratings[16] = 1   # Louis Theroux: Law & Disorder (2008)\n",
    "my_ratings[18] = 1   # Nothing to Declare (Rien à déclarer)\n",
    "my_ratings[21]  = 5   # Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
    "my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n",
    "\n",
    "print('\\nNew user ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0 :\n",
    "        print(f'Rated {my_ratings[i]} for  {bookList_df.loc[i,\"title\"]}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_ratings_matrices(books_df, n_synthetic_users=100):\n",
    "    n_books = len(books_df)\n",
    "    \n",
    "    # Create matrices\n",
    "    Y = np.zeros((n_books, n_synthetic_users))\n",
    "    R = np.zeros((n_books, n_synthetic_users))\n",
    "    \n",
    "    for book_idx in range(n_books):\n",
    "        avg_rating = books_df.loc[book_idx, 'average_rating']\n",
    "        n_ratings = books_df.loc[book_idx, 'ratings_count']\n",
    "        \n",
    "        if pd.notna(avg_rating) and n_ratings > 0:\n",
    "            # Generate synthetic ratings around the average rating\n",
    "            # for a random subset of users\n",
    "            n_users_who_rated = min(int(n_ratings/100), n_synthetic_users)  # Scale down the number\n",
    "            rating_users = np.random.choice(n_synthetic_users, n_users_who_rated, replace=False)\n",
    "            \n",
    "            # Generate ratings with some noise around the average\n",
    "            synthetic_ratings = np.random.normal(avg_rating, 0.5, n_users_who_rated)\n",
    "            # Clip ratings to be between 1 and 5\n",
    "            synthetic_ratings = np.clip(synthetic_ratings, 1, 5)\n",
    "            \n",
    "            # Assign the ratings\n",
    "            Y[book_idx, rating_users] = synthetic_ratings\n",
    "            R[book_idx, rating_users] = 1\n",
    "    \n",
    "    return Y, R\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage:\n",
    "import pandas as pd\n",
    "books_df = pd.read_csv('books.csv')\n",
    "Y, R = create_user_ratings_matrices(books_df)\n",
    "\n",
    "# Save the matrices for future use\n",
    "np.savetxt('books_Y.csv', Y, delimiter=',')\n",
    "np.savetxt('books_R.csv', R, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of books: 11128\n",
      "Number of users: 105\n",
      "Number of features: 100\n",
      "Total number of ratings: 321729\n",
      "Sparsity: 72.47%\n"
     ]
    }
   ],
   "source": [
    "def get_books_users_features_count(Y, num_features=100):\n",
    "    \"\"\"\n",
    "    Computes the number of books, users, and features from the ratings matrix\n",
    "    \n",
    "    Args:\n",
    "        Y (ndarray): Ratings matrix where rows are books and columns are users\n",
    "        num_features (int): Number of latent features (default=100)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (num_books, num_users, num_features)\n",
    "    \"\"\"\n",
    "    num_books, num_users = Y.shape\n",
    "    \n",
    "    print(f\"Number of books: {num_books}\")\n",
    "    print(f\"Number of users: {num_users}\")\n",
    "    print(f\"Number of features: {num_features}\")\n",
    "    print(f\"Total number of ratings: {np.count_nonzero(Y)}\")\n",
    "    print(f\"Sparsity: {(1 - np.count_nonzero(Y)/(num_books*num_users))*100:.2f}%\")\n",
    "    \n",
    "    return num_books, num_users, num_features\n",
    "\n",
    "# Usage:\n",
    "num_books, num_users, num_features = get_books_users_features_count(Y)\n",
    "\n",
    "# You can also specify a different number of features:\n",
    "# num_books, num_users, num_features = get_books_users_features_count(Y, num_features=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad Y with zeros to match my_ratings size\n",
    "padding_size = 11128 - Y.shape[0]\n",
    "if padding_size > 0:\n",
    "    Y = np.pad(Y, ((0, padding_size), (0, 0)), mode='constant')\n",
    "    R = np.pad(R, ((0, padding_size), (0, 0)), mode='constant')\n",
    "\n",
    "# Then concatenate\n",
    "Y = np.c_[my_ratings, Y]\n",
    "R = np.c_[(my_ratings != 0).astype(int), R]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recsys_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeRatings(Y, R):\n",
    "    \"\"\"\n",
    "    Normalize Y by subtracting the mean of each movie's ratings\n",
    "    Args:\n",
    "      Y (ndarray (num_movies,num_users)): The utility matrix\n",
    "      R (ndarray (num_movies,num_users)): Indicator matrix for Y\n",
    "    Returns:\n",
    "      Ynorm (ndarray (num_movies,num_users)): Normalized Y utility matrix\n",
    "      Ymean (ndarray (num_movies,1)): Mean rating for each movie\n",
    "    \"\"\"\n",
    "    Ymean = (np.sum(Y*R, axis=1)/(np.sum(R, axis=1)+1e-12)).reshape(-1,1)\n",
    "    Ynorm = Y - np.multiply(Ymean, R) \n",
    "    return(Ynorm, Ymean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y    = np.c_[my_ratings, Y]\n",
    "R    = np.c_[(my_ratings != 0).astype(int), R]\n",
    "\n",
    "# Normalize the Dataset\n",
    "Ynorm, Ymean = normalizeRatings(Y, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11128, 105)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Useful Values\n",
    "num_movies, num_users = Y.shape\n",
    "num_features = 100\n",
    "\n",
    "# Set Initial Parameters (W, X), use tf.Variable to track these variables\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "W = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\n",
    "X = tf.Variable(tf.random.normal((num_books, num_features),dtype=tf.float64),  name='X')\n",
    "b = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\n",
    "\n",
    "# Instantiate an optimizer.\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofi_cost_func_v(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Vectorized for speed. Uses tensorflow operations to be compatible with custom training loop.\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 17214531.6\n",
      "Training loss at iteration 20: 448773.1\n",
      "Training loss at iteration 40: 183847.4\n",
      "Training loss at iteration 60: 113176.6\n",
      "Training loss at iteration 80: 80312.5\n",
      "Training loss at iteration 100: 61577.4\n",
      "Training loss at iteration 120: 49255.2\n",
      "Training loss at iteration 140: 40278.6\n",
      "Training loss at iteration 160: 33278.0\n",
      "Training loss at iteration 180: 27614.9\n"
     ]
    }
   ],
   "source": [
    "iterations = 200\n",
    "lambda_ = 1\n",
    "for iter in range(iterations):\n",
    "    # Use TensorFlow’s GradientTape\n",
    "    # to record the operations used to compute the cost \n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # Compute the cost (forward pass included in cost)\n",
    "        cost_value = cofi_cost_func_v(X, W, b, Ynorm, R, lambda_)\n",
    "\n",
    "    # Use the gradient tape to automatically retrieve\n",
    "    # the gradients of the trainable variables with respect to the loss\n",
    "    grads = tape.gradient( cost_value, [X,W,b] )\n",
    "\n",
    "    # Run one step of gradient descent by updating\n",
    "    # the value of the variables to minimize the loss.\n",
    "    optimizer.apply_gradients( zip(grads, [X,W,b]) )\n",
    "\n",
    "    # Log periodically.\n",
    "    if iter % 20 == 0:\n",
    "        print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting rating 5.62 for Book The Mysterious Affair at Styles (Hercule Poirot  #1)\n",
      "Predicting rating 5.14 for Book Forgiven (Firstborn  #2)\n",
      "Predicting rating 5.07 for Book The Monster at the End of this Book\n",
      "Predicting rating 4.98 for Book Fullmetal Alchemist  Vol. 10\n",
      "Predicting rating 4.94 for Book Why Are All The Black Kids Sitting Together in the Cafeteria?: A Psychologist Explains the Development of Racial Identity\n",
      "Predicting rating 4.94 for Book Death Note  Vol. 1: Boredom (Death Note  #1)\n",
      "Predicting rating 4.89 for Book Found (Firstborn  #3)\n",
      "Predicting rating 4.89 for Book Nineteen Eighty-Four\n",
      "Predicting rating 4.87 for Book Exodus\n",
      "Predicting rating 4.86 for Book The Book Thief\n",
      "Predicting rating 4.85 for Book The Shining\n",
      "\n",
      "\n",
      "Original vs Predicted ratings:\n",
      "\n",
      "Original 5.0, Predicted 4.93 for Harry Potter and the Order of the Phoenix (Harry Potter  #5)\n",
      "Original 2.0, Predicted 2.10 for Harry Potter and the Chamber of Secrets (Harry Potter  #2)\n",
      "Original 5.0, Predicted 4.91 for Harry Potter Boxed Set  Books 1-5 (Harry Potter  #1-5)\n",
      "Original 5.0, Predicted 5.01 for Unauthorized Harry Potter Book Seven News: \"Half-Blood Prince\" Analysis and Speculation\n",
      "Original 3.0, Predicted 3.07 for The Ultimate Hitchhiker's Guide to the Galaxy (Hitchhiker's Guide to the Galaxy  #1-5)\n",
      "Original 5.0, Predicted 4.91 for The Hitchhiker's Guide to the Galaxy (Hitchhiker's Guide to the Galaxy  #1)\n",
      "Original 2.0, Predicted 2.13 for The Hitchhiker's Guide to the Galaxy (Hitchhiker's Guide to the Galaxy  #1)\n",
      "Original 5.0, Predicted 4.94 for A Short History of Nearly Everything\n",
      "Original 5.0, Predicted 4.80 for Bill Bryson's African Diary\n",
      "Original 3.0, Predicted 3.02 for Bryson's Dictionary of Troublesome Words: A Writer's Guide to Getting It Right\n",
      "Original 1.0, Predicted 1.20 for I'm a Stranger Here Myself: Notes on Returning to America After Twenty Years Away\n",
      "Original 1.0, Predicted 1.16 for Neither Here nor There: Travels in Europe\n",
      "Original 5.0, Predicted 4.93 for J.R.R. Tolkien 4-Book Boxed Set: The Hobbit and The Lord of the Rings\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction using trained weights and biases\n",
    "p = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()\n",
    "\n",
    "#restore the mean\n",
    "pm = p + Ymean\n",
    "\n",
    "my_predictions = pm[:,0]\n",
    "\n",
    "# sort predictions\n",
    "ix = tf.argsort(my_predictions, direction='DESCENDING')\n",
    "\n",
    "for i in range(17):\n",
    "    j = ix[i]\n",
    "    if j not in my_rated:\n",
    "        print(f'Predicting rating {my_predictions[j]:0.2f} for Book {bookList[j]}')\n",
    "\n",
    "print('\\n\\nOriginal vs Predicted ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {bookList[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
